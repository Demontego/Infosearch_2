{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "State notebook purpose here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import xgboost as xgb\n",
    "from scipy.special import expit\n",
    "from collections import defaultdict\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from numba import jit\n",
    "from multiprocessing import Pool\n",
    "from catboost import CatBoost, Pool, MetricVisualizer\n",
    "from copy import deepcopy\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    X_data, y_data, qid_data = load_svmlight_file(path, query_id=True)\n",
    "    sorted_by_qid_idxs = np.argsort(qid_data, kind = 'mergesort')\n",
    "    qid_data = qid_data[sorted_by_qid_idxs]\n",
    "    X_data = X_data[sorted_by_qid_idxs]\n",
    "    y_data = y_data[sorted_by_qid_idxs]\n",
    "    group_sizes = np.unique(qid_data, return_counts=True)[1]\n",
    "    return X_data, y_data, qid_data, group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='l2r/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, qid_train, group_train = load_data(data_folder +'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test, qid_test, group_test = load_data(data_folder +'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473134,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19944,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling\n",
    "Do work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(y, k=5):\n",
    "    k_=min(len(y),k)\n",
    "    return np.sum([(np.power(2, y[i]) - 1) / (np.log2(i + 2) + 1) for i in range(k_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_dcg(scores):\n",
    "    scores = [score for score in np.sort(scores, kind='mergesort')[::-1]]\n",
    "    return dcg(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(true_scores):\n",
    "    len_of_scores = len(true_scores)\n",
    "    for i in range(len_of_scores):\n",
    "        for j in range(i, len_of_scores):\n",
    "            if true_scores[i] > true_scores[j]:\n",
    "                yield (i, j)\n",
    "\n",
    "def delta_ndcg(i,j,idcg, y_true):\n",
    "    i_pow = np.power(2, y_true[i]) - 1\n",
    "    j_pow = np.power(2, y_true[j]) - 1\n",
    "    i_log = np.log2(i + 2)\n",
    "    j_log = np.log2(j + 2)\n",
    "    return abs(i_pow / j_log - i_pow / i_log + j_pow / i_log - j_pow / j_log) / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambdas_and_w(args):\n",
    "    y_true, y_pred, qid = args\n",
    "    sorted_indexes = np.argsort(y_pred, kind='mergesort')[::-1]\n",
    "    rev_indexes = np.argsort(sorted_indexes)\n",
    "    #print(sorted_indexes, rev_indexes)\n",
    "    y_true = y_true[sorted_indexes]\n",
    "    y_pred = y_pred[sorted_indexes]\n",
    "    dcg_real=ideal_dcg(y_true)\n",
    "    lambdas=np.zeros(len(y_true))\n",
    "    w=np.zeros(len(y_true))\n",
    "    for i, j in get_pairs(y_true):\n",
    "        d_ndcg=delta_ndcg(i,j,dcg_real, y_true)\n",
    "        #print(i,j,d_ndcg)\n",
    "        diff=min(abs(y_pred[i]-y_pred[j]),20)\n",
    "        sig=expit(-diff)\n",
    "        lambda_val = -d_ndcg * sig\n",
    "        w_val = sig * (1 - sig) * d_ndcg\n",
    "        #print(i,j,d_ndcg,diff,sig, lambda_val, w_val)\n",
    "        lambdas[i] += lambda_val\n",
    "        lambdas[j] -= lambda_val\n",
    "        w[i] += w_val\n",
    "        w[j] += w_val\n",
    "    #print(lambdas,w)\n",
    "    return lambdas[rev_indexes], w[rev_indexes], qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(pred, dtrain):\n",
    "    Y = np.array(dtrain.get_label())\n",
    "    pred=np.array(pred)\n",
    "    qids=np.unique(qid_train)\n",
    "    true_scores = [Y[np.where(qid_train==qid)] for qid in qids]\n",
    "    pred_scores=[pred[np.where(qid_train==qid)] for qid in qids]\n",
    "    grad = np.zeros(Y.shape)\n",
    "    hess = np.zeros(Y.shape)\n",
    "    pool = Pool(6)\n",
    "    for lambda_val, w_val, qid in pool.map(lambdas_and_w,\n",
    "                                             zip(true_scores, pred_scores, qids),\n",
    "                                             chunksize=1):\n",
    "        grad[np.where(qid_train==qid)] = lambda_val\n",
    "        hess[np.where(qid_train==qid)] = w_val\n",
    "#     for true,pred,qid in zip(true_scores, pred_scores, qids):\n",
    "#         lambda_val, w_val=lambdas_and_w(y_true=true,y_pred=pred)\n",
    "#         grad[np.where(qid_train==qid)] = lambda_val\n",
    "#         hess[np.where(qid_train==qid)] = w_val\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtrain.set_group(group_train)\n",
    "dtest = xgb.DMatrix(data = X_test)\n",
    "dtest.set_group(group_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучал поэтапно, по 100 итерации, на каждом этапе уменьшал 'eta' и увеличивал глубину дерева. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "params = {'eta': 0.5,  'max_depth': 10, 'eval_metric': 'ndcg@5','subsample': 0.5, 'num_parallel_tree': 6}#, 'tree_method': 'gpu_hist'}\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dtrain, 'train')],\n",
    "                        obj=gradient, xgb_model=\"my_xgboost_0.6_8_0.5_500.xgb\",\n",
    "                        verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model(\"my_xgboost_0.5_10_600.xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_my_xgboost_600.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(pred_qids, preds, filename):\n",
    "    fout = open(filename, 'w')\n",
    "    fout.write('QueryId,DocumentId\\n')\n",
    "    for qid in np.unique(pred_qids):\n",
    "        q_doc_idxs = np.argwhere(pred_qids == qid).ravel()\n",
    "        q_doc_scores = preds[q_doc_idxs]\n",
    "        sorted_doc_ids = 1 + q_doc_idxs[np.argsort(q_doc_scores)[::-1]]\n",
    "        for did in sorted_doc_ids:\n",
    "            fout.write('{0},{1}\\n'.format(qid, did))\n",
    "        \n",
    "    fout.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(qid_test,pred, 'eta-0.5_depth-10_600.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=qid_train\n",
    ")\n",
    "test = Pool(data=X_test, group_id=qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {\n",
    "    'iterations': 1000,\n",
    "    'custom_metric': ['NDCG:top=5'],\n",
    "    'verbose': False,\n",
    "    'subsample': 0.7\n",
    "}\n",
    "parameters = deepcopy(default_parameters)\n",
    "parameters['loss_function'] = 'YetiRankPairwise'\n",
    "parameters['train_dir'] = 'YetiRankPairwise'\n",
    "model_catboost = CatBoost(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost.fit(train, eval_set=train, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost.save_model(\"catboost1000.ctb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_catboost = model_catboost.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(qid_test,pred_catboost, 'catboost1000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_catboost.npy', pred_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission(filename):\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    fin = open(filename, 'r')\n",
    "    fin.readline()\n",
    "    for l in fin.readlines():\n",
    "        args = l.split(',')\n",
    "        args = [x for x in args if len(x) > 0]\n",
    "        if len(args) < 2:\n",
    "            continue\n",
    "        res1.append(args[0])\n",
    "        res2.append(int(args[1])-1)\n",
    "    fin.close()\n",
    "    return np.array(res1),np.array(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgboost= np.load('pred_my_xgboost_600.npy')\n",
    "qid_catboost,sub_catboost = load_submission('catboost1000.txt')\n",
    "qid_my,sub_my=load_submission('eta-0.5_depth-10_600.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_test_train=qid_test[np.where(sub_catboost==sub_my)]\n",
    "X_test_train=X_test[np.where(sub_catboost==sub_my)]\n",
    "y_pred_train=pred_xgboost[np.where(sub_catboost==sub_my)]\n",
    "group_test_train=np.unique(qid_test_train, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new= sparse.vstack([X_train, X_test_train])\n",
    "y_train_new=np.hstack((y_train,y_pred_train))\n",
    "group_train_new=np.hstack((group_train,group_test_train))\n",
    "qid_train_new=np.hstack((qid_train,qid_test_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_new(pred, dtrain):\n",
    "    Y = np.array(dtrain.get_label())\n",
    "    pred=np.array(pred)\n",
    "    qids=np.unique(qid_train_new)\n",
    "    true_scores = [Y[np.where(qid_train_new==qid)] for qid in qids]\n",
    "    pred_scores=[pred[np.where(qid_train_new==qid)] for qid in qids]\n",
    "    grad = np.zeros(Y.shape)\n",
    "    hess = np.zeros(Y.shape)\n",
    "    pool = Pool(6)\n",
    "    for lambda_val, w_val, qid in pool.map(lambdas_and_w,\n",
    "                                             zip(true_scores, pred_scores, qids),\n",
    "                                             chunksize=1):\n",
    "        grad[np.where(qid_train_new==qid)] = lambda_val\n",
    "        hess[np.where(qid_train_new==qid)] = w_val\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train_new, label = y_train_new)\n",
    "dtrain.set_group(group_train_new)\n",
    "dtest = xgb.DMatrix(data = X_test)\n",
    "dtest.set_group(group_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "params = {'eta': 0.5,  'max_depth': 8, 'eval_metric': 'ndcg@5','subsample': 0.5, 'num_parallel_tree': 6}#, 'tree_method': 'gpu_hist'}\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=500, evals=[(dtrain, 'dtrain')],\n",
    "                        obj=gradient_new,\n",
    "                        verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(qid_test,pred, 'easy.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ListNet\n",
    "Summarize findings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
